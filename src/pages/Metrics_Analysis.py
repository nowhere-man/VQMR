"""
Metrics åˆ†æä»»åŠ¡å¯¹æ¯”ï¼ˆé€‰æ‹©ä¸¤ä¸ª Metrics åˆ†æä»»åŠ¡ï¼Œå®æ—¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼Œä¸è½ç›˜ï¼‰
"""

from __future__ import annotations

import json
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from src.utils.bd_rate import bd_rate as _bd_rate, bd_metrics as _bd_metrics
from src.utils.streamlit_helpers import (
    jobs_root_dir as _jobs_root_dir,
    list_jobs,
    load_json_report,
    parse_rate_point as _parse_point,
    create_cpu_chart,
)


def _list_metrics_jobs(limit: int = 100) -> List[Dict[str, Any]]:
    return list_jobs("metrics_analysis/analyse_data.json", limit=limit, check_status=True)


def _load_analyse(job_id: str) -> Dict[str, Any]:
    return load_json_report(job_id, "metrics_analysis/analyse_data.json")


def _metric_value(metrics: Dict[str, Any], name: str, field: str) -> Optional[float]:
    block = metrics.get(name) or {}
    if not isinstance(block, dict):
        return None
    summary = block.get("summary") or {}
    if isinstance(summary, dict) and field in summary:
        return summary.get(field)
    return block.get(field)


def _build_rows(data: Dict[str, Any], side_label: str) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """æ„å»ºæŒ‡æ ‡æ•°æ®è¡Œå’Œæ€§èƒ½æ•°æ®è¡Œ"""
    rows: List[Dict[str, Any]] = []
    perf_rows: List[Dict[str, Any]] = []
    entries = data.get("entries") or []
    for entry in entries:
        video = entry.get("source")
        for item in entry.get("encoded") or []:
            rc, val = _parse_point(item.get("label", ""))
            metrics = item.get("metrics") or {}
            rows.append(
                {
                    "Video": video,
                    "Side": side_label,
                    "RC": rc,
                    "Point": val,
                    "Bitrate_kbps": ((item.get("bitrate") or {}).get("avg_bitrate_bps") or item.get("avg_bitrate_bps") or 0) / 1000,
                    "PSNR": _metric_value(metrics, "psnr", "psnr_avg"),
                    "SSIM": _metric_value(metrics, "ssim", "ssim_avg"),
                    "VMAF": _metric_value(metrics, "vmaf", "vmaf_mean"),
                    "VMAF-NEG": _metric_value(metrics, "vmaf_neg", "vmaf_neg_mean") or _metric_value(metrics, "vmaf", "vmaf_neg_mean"),
                }
            )
            # æå–æ€§èƒ½æ•°æ®
            perf = item.get("performance") or {}
            if perf:
                perf_rows.append({
                    "Video": video,
                    "Side": side_label,
                    "Point": val,
                    "FPS": perf.get("encoding_fps"),
                    "CPU Avg(%)": perf.get("cpu_avg_percent"),
                    "CPU Max(%)": perf.get("cpu_max_percent"),
                    "Total Time(s)": perf.get("total_encoding_time_s"),
                    "Frames": perf.get("total_frames"),
                    "cpu_samples": perf.get("cpu_samples", []),
                })
    return rows, perf_rows


def _build_bd_rows(df: pd.DataFrame) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    bd_rate_rows: List[Dict[str, Any]] = []
    bd_metric_rows: List[Dict[str, Any]] = []
    grouped = df.groupby("Video")
    for video, g in grouped:
        base = g[g["Side"] == "A"]
        exp = g[g["Side"] == "B"]
        if base.empty or exp.empty:
            continue
        merge = base.merge(exp, on=["Video", "RC", "Point"], suffixes=("_base", "_exp"))
        if merge.empty:
            continue
        def _collect(col_base: str, col_exp: str) -> Tuple[List[float], List[float], List[float], List[float]]:
            merged = merge.dropna(subset=[col_base, col_exp, "Bitrate_kbps_base", "Bitrate_kbps_exp"])
            if merged.empty:
                return [], [], [], []
            return (
                merged["Bitrate_kbps_base"].tolist(),
                merged[col_base].tolist(),
                merged["Bitrate_kbps_exp"].tolist(),
                merged[col_exp].tolist(),
            )

        base_rates, base_psnr, exp_rates, exp_psnr = _collect("PSNR_base", "PSNR_exp")
        _, base_ssim, _, exp_ssim = _collect("SSIM_base", "SSIM_exp")
        _, base_vmaf, _, exp_vmaf = _collect("VMAF_base", "VMAF_exp")
        _, base_vn, _, exp_vn = _collect("VMAF-NEG_base", "VMAF-NEG_exp")
        # BD-Rate
        bd_rate_rows.append(
            {
                "Video": video,
                "BD-Rate PSNR (%)": _bd_rate(base_rates, base_psnr, exp_rates, exp_psnr),
                "BD-Rate SSIM (%)": _bd_rate(base_rates, base_ssim, exp_rates, exp_ssim),
                "BD-Rate VMAF (%)": _bd_rate(base_rates, base_vmaf, exp_rates, exp_vmaf),
                "BD-Rate VMAF-NEG (%)": _bd_rate(base_rates, base_vn, exp_rates, exp_vn),
            }
        )
        # BD-Metrics
        bd_metric_rows.append(
            {
                "Video": video,
                "BD PSNR": _bd_metrics(base_rates, base_psnr, exp_rates, exp_psnr),
                "BD SSIM": _bd_metrics(base_rates, base_ssim, exp_rates, exp_ssim),
                "BD VMAF": _bd_metrics(base_rates, base_vmaf, exp_rates, exp_vmaf),
                "BD VMAF-NEG": _bd_metrics(base_rates, base_vn, exp_rates, exp_vn),
            }
        )
    return bd_rate_rows, bd_metric_rows


st.set_page_config(page_title="Metricsåˆ†æ", page_icon="ğŸ“Š", layout="wide")
st.markdown("<h1 style='text-align:center;'>ğŸ“Š Metricsåˆ†æ</h1>", unsafe_allow_html=True)

jobs = _list_metrics_jobs()
if len(jobs) < 2:
    st.info("éœ€è¦è‡³å°‘ä¸¤ä¸ªå·²å®Œæˆçš„Metricsåˆ†æä»»åŠ¡")
    st.stop()

options = [j["job_id"] for j in jobs if j["status_ok"]]
if len(options) < 2:
    st.info("ä»»åŠ¡æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
    st.stop()

col1, col2 = st.columns(2)
with col1:
    job_a = st.selectbox("ä»»åŠ¡ A", options=options, key="metrics_job_a")
with col2:
    job_b = st.selectbox("ä»»åŠ¡ B", options=[o for o in options if o != job_a], key="metrics_job_b")

if not job_a or not job_b:
    st.stop()

data_a = _load_analyse(job_a)
data_b = _load_analyse(job_b)

rows_a, perf_rows_a = _build_rows(data_a, "A")
rows_b, perf_rows_b = _build_rows(data_b, "B")
rows = rows_a + rows_b
perf_rows = perf_rows_a + perf_rows_b
df = pd.DataFrame(rows)
if df.empty:
    st.warning("æ²¡æœ‰å¯ç”¨äºå¯¹æ¯”çš„æŒ‡æ ‡æ•°æ®ã€‚")
    st.stop()

df = df.sort_values(by=["Video", "RC", "Point", "Side"])

# ========== ä¾§è¾¹æ ç›®å½• ==========
with st.sidebar:
    st.markdown("### ğŸ“‘ Contents")
    st.markdown("""
- [Metrics](#metrics)
  - [A vs B å¯¹æ¯”](#a-vs-b-å¯¹æ¯”)
- [BD-Rate](#bd-rate)
- [BD-Metrics](#bd-metrics)
- [Performance](#performance)
  - [Delta](#perf-diff)
  - [CPU Usage](#cpu-chart)
  - [Detalis](#perf-details)
- [Machine Info](#ç¯å¢ƒä¿¡æ¯)
""", unsafe_allow_html=True)

# å¹³æ»‘æ»šåŠ¨ CSS
st.markdown("""
<style>
html {
    scroll-behavior: smooth;
}
</style>
""", unsafe_allow_html=True)

st.header("Metrics", anchor="metrics")
st.dataframe(df, use_container_width=True, hide_index=True)

base_df = df[df["Side"] == "A"]
exp_df = df[df["Side"] == "B"]
merged = base_df.merge(exp_df, on=["Video", "RC", "Point"], suffixes=("_base", "_exp"))
if not merged.empty:
    merged["Bitrate Î”%"] = ((merged["Bitrate_kbps_exp"] - merged["Bitrate_kbps_base"]) / merged["Bitrate_kbps_base"].replace(0, pd.NA)) * 100
    merged["PSNR Î”"] = merged["PSNR_exp"] - merged["PSNR_base"]
    merged["SSIM Î”"] = merged["SSIM_exp"] - merged["SSIM_base"]
    merged["VMAF Î”"] = merged["VMAF_exp"] - merged["VMAF_base"]
    merged["VMAF-NEG Î”"] = merged["VMAF-NEG_exp"] - merged["VMAF-NEG_base"]
    st.subheader("A vs B å¯¹æ¯”", anchor="a-vs-b-å¯¹æ¯”")
    st.dataframe(
        merged[
            [
                "Video",
                "RC",
                "Point",
                "Bitrate_kbps_base",
                "Bitrate_kbps_exp",
                "Bitrate Î”%",
                "PSNR_base",
                "PSNR_exp",
                "PSNR Î”",
                "SSIM_base",
                "SSIM_exp",
                "SSIM Î”",
                "VMAF_base",
                "VMAF_exp",
                "VMAF Î”",
                "VMAF-NEG_base",
                "VMAF-NEG_exp",
                "VMAF-NEG Î”",
            ]
        ].sort_values(by=["Video", "Point"]),
        use_container_width=True,
        hide_index=True,
    )

st.header("BD-Rate", anchor="bd-rate")
bd_rate_rows, bd_metric_rows = _build_bd_rows(merged)
if bd_rate_rows:
    st.dataframe(pd.DataFrame(bd_rate_rows), use_container_width=True, hide_index=True)
else:
    st.info("æ— æ³•è®¡ç®— BD-Rateï¼ˆç‚¹ä½ä¸è¶³æˆ–ç¼ºå°‘å…±åŒè§†é¢‘ï¼‰ã€‚")

st.header("BD-Metrics", anchor="bd-metrics")
if bd_metric_rows:
    st.dataframe(pd.DataFrame(bd_metric_rows), use_container_width=True, hide_index=True)
else:
    st.info("æ— æ³•è®¡ç®— BD-Metricsï¼ˆç‚¹ä½ä¸è¶³æˆ–ç¼ºå°‘å…±åŒè§†é¢‘ï¼‰ã€‚")

# ========== Performance ==========
st.header("Performance", anchor="performance")

if perf_rows:
    df_perf = pd.DataFrame(perf_rows)

    # 1. æ±‡æ€»Diffè¡¨æ ¼
    st.subheader("Delta", anchor="perf-diff")
    base_perf = df_perf[df_perf["Side"] == "A"]
    exp_perf = df_perf[df_perf["Side"] == "B"]
    merged_perf = base_perf.merge(
        exp_perf,
        on=["Video", "Point"],
        suffixes=("_base", "_exp"),
    )
    if not merged_perf.empty:
        merged_perf["Î” FPS"] = merged_perf["FPS_exp"] - merged_perf["FPS_base"]
        merged_perf["Î” CPU Avg(%)"] = merged_perf["CPU Avg(%)_exp"] - merged_perf["CPU Avg(%)_base"]

        diff_perf_df = merged_perf[
            ["Video", "Point", "FPS_base", "FPS_exp", "Î” FPS", "CPU Avg(%)_base", "CPU Avg(%)_exp", "Î” CPU Avg(%)"]
        ].rename(columns={
            "FPS_base": "A FPS",
            "FPS_exp": "B FPS",
            "CPU Avg(%)_base": "A CPU(%)",
            "CPU Avg(%)_exp": "B CPU(%)",
        }).sort_values(by=["Video", "Point"]).reset_index(drop=True)

        # åˆå¹¶åŒä¸€è§†é¢‘çš„åç§°
        prev_video = None
        for idx in diff_perf_df.index:
            if diff_perf_df.at[idx, "Video"] == prev_video:
                diff_perf_df.at[idx, "Video"] = ""
            else:
                prev_video = diff_perf_df.at[idx, "Video"]

        def _color_perf_diff(val):
            if pd.isna(val) or not isinstance(val, (int, float)):
                return ""
            if val > 0:
                return "color: green"
            elif val < 0:
                return "color: red"
            return ""

        styled_perf = diff_perf_df.style.applymap(_color_perf_diff, subset=["Î” FPS", "Î” CPU Avg(%)"])
        st.dataframe(styled_perf, use_container_width=True, hide_index=True)

    # 2. CPUæŠ˜çº¿å›¾
    st.subheader("CPU Usage", anchor="cpu-chart")

    # é€‰æ‹©è§†é¢‘å’Œç‚¹ä½
    video_list_perf = df_perf["Video"].unique().tolist()
    col_sel_perf1, col_sel_perf2 = st.columns(2)
    with col_sel_perf1:
        selected_video_perf = st.selectbox("é€‰æ‹©è§†é¢‘", video_list_perf, key="perf_video")
    with col_sel_perf2:
        point_list_perf = df_perf[df_perf["Video"] == selected_video_perf]["Point"].unique().tolist()
        selected_point_perf = st.selectbox("é€‰æ‹©ç ç‡ç‚¹ä½", point_list_perf, key="perf_point")

    # èšåˆé—´éš”é€‰æ‹©
    agg_interval = st.slider("èšåˆé—´éš” (ms)", min_value=100, max_value=1000, value=100, step=100, key="cpu_agg")

    # è·å–å¯¹åº”çš„CPUé‡‡æ ·æ•°æ®
    base_samples: List[float] = []
    exp_samples: List[float] = []
    for _, row in df_perf.iterrows():
        if row["Video"] == selected_video_perf and row["Point"] == selected_point_perf:
            if row["Side"] == "A":
                base_samples = row.get("cpu_samples", []) or []
            else:
                exp_samples = row.get("cpu_samples", []) or []

    if base_samples or exp_samples:
        fig_cpu = create_cpu_chart(
            base_samples=base_samples,
            exp_samples=exp_samples,
            agg_interval=agg_interval,
            title=f"CPUå ç”¨ç‡ - {selected_video_perf} ({selected_point_perf})",
            base_label="A",
            exp_label="B",
        )
        st.plotly_chart(fig_cpu, use_container_width=True)
    else:
        st.info("è¯¥è§†é¢‘/ç‚¹ä½æ²¡æœ‰CPUé‡‡æ ·æ•°æ®ã€‚")

    # 3. è¯¦ç»†æ•°æ®è¡¨æ ¼ï¼ˆé»˜è®¤æŠ˜å ï¼‰
    st.subheader("Details", anchor="perf-details")
    with st.expander("æŸ¥çœ‹è¯¦ç»†æ€§èƒ½æ•°æ®", expanded=False):
        # ç§»é™¤ cpu_samples åˆ—ç”¨äºå±•ç¤º
        df_perf_detail = df_perf.drop(columns=["cpu_samples"], errors="ignore")
        st.dataframe(df_perf_detail.sort_values(by=["Video", "Point", "Side"]), use_container_width=True, hide_index=True)
else:
    st.info("æš‚æ— æ€§èƒ½æ•°æ®ã€‚è¯·ç¡®ä¿ç¼–ç ä»»åŠ¡å·²å®Œæˆå¹¶é‡‡é›†äº†æ€§èƒ½æ•°æ®ã€‚")

st.header("Machine Info", anchor="ç¯å¢ƒä¿¡æ¯")

def _format_env_info(env: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–ç¯å¢ƒä¿¡æ¯ä¸º Markdown åˆ—è¡¨"""
    if not env:
        return "æœªé‡‡é›†åˆ°ç¯å¢ƒä¿¡æ¯ã€‚"

    lines = []

    # ç³»ç»Ÿä¿¡æ¯
    lines.append("**ç³»ç»Ÿä¿¡æ¯**")
    os_name = env.get('os', 'N/A')
    hostname = env.get('hostname', 'N/A')
    linux_distro = env.get('linux_distro', '')

    lines.append(f"- **æ“ä½œç³»ç»Ÿ**: {os_name}")
    lines.append(f"- **ä¸»æœºå**: {hostname}")
    if os_name == "Linux" and linux_distro:
        lines.append(f"- **å‘è¡Œç‰ˆ**: {linux_distro}")

    lines.append("")  # ç©ºè¡Œ

    # CPU ä¿¡æ¯
    lines.append("**CPU ä¿¡æ¯**")
    cpu_model = env.get('cpu_model', env.get('cpu', 'N/A'))
    cpu_arch = env.get('cpu_arch', 'N/A')
    phys_cores = env.get('cpu_phys_cores', env.get('phys_cores', 'N/A'))
    log_cores = env.get('cpu_log_cores', env.get('log_cores', 'N/A'))
    cpu_freq = env.get('cpu_freq_mhz', 'N/A')
    numa_nodes = env.get('numa_nodes', 'N/A')
    cpu_percent = env.get('cpu_percent_before', env.get('cpu_percent_start', 'N/A'))

    lines.append(f"- **CPU å‹å·**: {cpu_model}")
    lines.append(f"- **CPU æ¶æ„**: {cpu_arch}")
    lines.append(f"- **æ ¸å¿ƒ/çº¿ç¨‹**: {phys_cores}C/{log_cores}T")
    lines.append(f"- **CPU ä¸»é¢‘**: {cpu_freq} MHz")
    lines.append(f"- **NUMA Nodes**: {numa_nodes}")
    lines.append(f"- **CPU å ç”¨ç‡**: {cpu_percent}%")

    lines.append("")  # ç©ºè¡Œ

    # å†…å­˜ä¿¡æ¯
    lines.append("**å†…å­˜ä¿¡æ¯**")
    # å…¼å®¹æ–°æ—§æ ¼å¼
    mem_total_gb = env.get('mem_total_gb')
    mem_used_gb = env.get('mem_used_gb')
    mem_available_gb = env.get('mem_available_gb')
    mem_percent = env.get('mem_percent_used')

    # å¦‚æœæ˜¯æ—§æ ¼å¼ï¼ˆMBï¼‰ï¼Œè½¬æ¢ä¸º GB
    if mem_total_gb is None and env.get('mem_total_mb'):
        try:
            mem_total_gb = round(env.get('mem_total_mb') / 1024, 2)
        except (ValueError, TypeError):
            pass
    if mem_available_gb is None and env.get('mem_available_mb'):
        try:
            mem_available_gb = round(env.get('mem_available_mb') / 1024, 2)
        except (ValueError, TypeError):
            pass
    if mem_used_gb is None and mem_total_gb and mem_available_gb:
        mem_used_gb = round(mem_total_gb - mem_available_gb, 2)

    # è®¡ç®—å¯ç”¨ç‡
    mem_avail_percent = None
    if mem_percent is not None:
        mem_avail_percent = round(100 - mem_percent, 1)
    elif mem_total_gb and mem_available_gb:
        mem_avail_percent = round((mem_available_gb / mem_total_gb) * 100, 1)

    lines.append(f"- **æ€»å†…å­˜**: {mem_total_gb if mem_total_gb else 'N/A'} GB")
    lines.append(f"- **å·²ä½¿ç”¨**: {mem_used_gb if mem_used_gb else 'N/A'} GB")
    lines.append(f"- **å¯ç”¨å†…å­˜**: {mem_available_gb if mem_available_gb else 'N/A'} GB")
    lines.append(f"- **å¯ç”¨ç‡**: {mem_avail_percent if mem_avail_percent is not None else 'N/A'}%")

    lines.append("")  # ç©ºè¡Œ

    # å…¶ä»–ä¿¡æ¯
    lines.append("**å…¶ä»–ä¿¡æ¯**")
    exec_time = env.get('execution_time', 'N/A')
    lines.append(f"- **è¿è¡Œæ—¶é—´**: {exec_time}")

    return "\n".join(lines)

env_a = data_a.get("environment") or {}
env_b = data_b.get("environment") or {}
if env_a or env_b:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ä»»åŠ¡ A")
        st.markdown(_format_env_info(env_a))
    with col2:
        st.subheader("ä»»åŠ¡ B")
        st.markdown(_format_env_info(env_b))
else:
    st.info("æœªé‡‡é›†åˆ°ç¯å¢ƒä¿¡æ¯ã€‚")
